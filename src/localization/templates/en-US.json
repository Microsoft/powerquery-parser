{
    "error_common_invariantError_1_details": "InvariantError: {} - {}",
    "error_common_invariantError_2_noDetails": "InvariantError: {}",
    "error_common_unknown": "An unknown error was encountered, innerError: {}",
    "error_lex_badLineNumber_1_greaterThanNumLines": "lineNumber is greater than or equal to the number of lines",
    "error_lex_badLineNumber_2_lessThanZero": "lineNumber is less than or equal 0",
    "error_lex_badRange_1_lineNumberEnd_greaterThanLineLength": "end.lineCodeUnit is higher than line's length",
    "error_lex_badRange_2_lineNumberEnd_greaterThanLineNumbers": "end.lineNumber is higher than State's number of lines",
    "error_lex_badRange_3_lineNumberStart_greaterThanLineLength": "start.lineCodeUnit is higher than line's length",
    "error_lex_badRange_4_lineNumberStart_greaterThanLineNumberEnd": "start.lineNumber is larger than end.lineNumber",
    "error_lex_badRange_5_lineNumberStart_greaterThanNumLines": "start.lineNumber is higher than State's number of lines.",
    "error_lex_badRange_6_lineNumberStart_lessThanZero": "start.lineNumber is less than 0",
    "error_lex_badRange_7_sameLine_codeUnitStartGreaterThanCodeUnitEnd": "Start and end shared the same line, but start.lineCodeUnit was higher than end.lineCodeUnit",
    "error_lex_badState": "The lexer encountered an error last run. Either feed the lexer more text or review lastError",
    "error_lex_endOfStream": "The lexer reached end-of-stream",
    "error_lex_endOfStreamPartwayRead": "While attempting to read a token the document stream ended part way through",
    "error_lex_expectedKind_1_hex": "Expected a hex literal",
    "error_lex_expectedKind_2_keywordOrIdentifier": "Expected a keyword or identifier",
    "error_lex_expectedKind_3_numeric": "Expected a numeric literal",
    "error_lex_lineMap": "Error on line(s): {}",
    "error_lex_unexpectedRead": "Unexpected read during tokenization",
    "error_lex_unterminatedMultilineToken_1_comment": "Unterminated multiline comment",
    "error_lex_unterminatedMultilineToken_2_quotedIdentifier": "Unterminated quoted identifier",
    "error_lex_unterminatedMultilineToken_3_string": "Unterminated string",
    "error_parse_csvContinuation_1_danglingComma": "Did you leave a dangling comma?",
    "error_parse_csvContinuation_2_letExpression": "A comma cannot proceed an 'in'",
    "error_parse_expectAnyTokenKind_1_other": "Expected to find one of the following, but a {} was found instead: {}",
    "error_parse_expectAnyTokenKind_2_endOfStream": "Expected to find one of the following, but the end-of-stream was reached instead: {}",
    "error_parse_expectGeneralizedIdentifier_1_other": "Expected to find a generalized identifier",
    "error_parse_expectGeneralizedIdentifier_2_endOfStream": "Expected to find a generalized identifier but the end-of-stream was reached first",
    "error_parse_expectTokenKind_1_other": "Expected to find a {}, but a {} was found instead",
    "error_parse_expectTokenKind_2_endOfStream": "Expected to find a {}, but the end-of-stream was reached instead",
    "error_parse_invalidPrimitiveType": "Expected to find a primitive literal, but a {} was found instead",
    "error_parse_requiredParameterAfterOptional": "You cannot have a non-optional parameter after an optional parameter",
    "error_parse_unterminated_bracket": "Unterminated bracket",
    "error_parse_unterminated_parenthesis": "Unterminated parenthesis",
    "error_parse_unusedTokens": "Finished parsing but more tokens remain",
    "tokenKind_ampersand": "ampersand <'&'>",
    "tokenKind_asterisk": "asterisk <'*'>",
    "tokenKind_atSign": "at sign <'@'>",
    "tokenKind_bang": "exclamation mark <'!'>",
    "tokenKind_comma": "comma <','>",
    "tokenKind_division": "division operator <'/'>",
    "tokenKind_dotDot": "dot dot <'..'>",
    "tokenKind_ellipsis": "ellipsis <'...'>",
    "tokenKind_equal": "equal operator <'='>",
    "tokenKind_fatArrow": "goes to ('=>')",
    "tokenKind_greaterThan": "greater than operator ('>')",
    "tokenKind_greaterThanEqualTo": "greater than or equal to operator ('>=')",
    "tokenKind_hexLiteral": "hex literal",
    "tokenKind_identifier": "identifier",
    "tokenKind_keywordAnd": "keyword <'and'>",
    "tokenKind_keywordAs": "keyword <'as'>",
    "tokenKind_keywordEach": "keyword <'each'>",
    "tokenKind_keywordElse": "keyword <'else'>",
    "tokenKind_keywordError": "keyword <'error'>",
    "tokenKind_keywordFalse": "keyword <'false'>",
    "tokenKind_keywordHashBinary": "keyword <'#binary'>",
    "tokenKind_keywordHashDate": "keyword <'#date'>",
    "tokenKind_keywordHashDateTime": "keyword <'#datetime'>",
    "tokenKind_keywordHashDateTimeZone": "keyword <'#datetimezone'>",
    "tokenKind_keywordHashDuration": "keyword <'#duration'>",
    "tokenKind_keywordHashInfinity": "keyword <'#infinity'>",
    "tokenKind_keywordHashNan": "keyword <'#nan'>",
    "tokenKind_keywordHashSections": "keyword <'#sections'>",
    "tokenKind_keywordHashShared": "keyword <'#shared'>",
    "tokenKind_keywordHashTable": "keyword <'#table'>",
    "tokenKind_keywordHashTime": "keyword <'#time'>",
    "tokenKind_keywordIf": "keyword <'if'>",
    "tokenKind_keywordIn": "keyword <'in'>",
    "tokenKind_keywordIs": "keyword <'is'>",
    "tokenKind_keywordLet": "keyword <'let'>",
    "tokenKind_keywordMeta": "keyword <'meta'>",
    "tokenKind_keywordNot": "keyword <'not'>",
    "tokenKind_keywordOr": "keyword <'or'>",
    "tokenKind_keywordOtherwise": "keyword <'otherwise'>",
    "tokenKind_keywordSection": "keyword <'section'>",
    "tokenKind_keywordShared": "keyword <'shared'>",
    "tokenKind_keywordThen": "keyword <'then'>",
    "tokenKind_keywordTrue": "keyword <'true'>",
    "tokenKind_keywordTry": "keyword <'try'>",
    "tokenKind_keywordType": "keyword <'type'>",
    "tokenKind_leftBrace": "left brace <'{'>",
    "tokenKind_leftBracket": "left bracket <'['>",
    "tokenKind_leftParenthesis": "left parenthesis <'('>",
    "tokenKind_lessThan": "less than operator ('<')",
    "tokenKind_lessThanEqualTo": "less than or equal to operator ('<=')",
    "tokenKind_minus": "minus <'-'>",
    "tokenKind_notEqual": "not equal to operator ('<>')",
    "tokenKind_nullLiteral": "<'null'>",
    "tokenKind_numericLiteral": "numeric literal",
    "tokenKind_plus": "addition operator <'+'>",
    "tokenKind_questionMark": "question mark <'?'>",
    "tokenKind_rightBrace": "right brace <'}'>",
    "tokenKind_rightBracket": "right bracket <']'>",
    "tokenKind_rightParenthesis": "right parenthesis <')'>",
    "tokenKind_semicolon": "semicolon <';'>",
    "tokenKind_stringLiteral": "string"
}