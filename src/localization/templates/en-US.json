{
    "error_common_invariantError_1_details": "InvariantError: {} - {}",
    "error_common_invariantError_2_noDetails": "InvariantError: {}",
    "error_common_unknown": "An unknown error was encountered, innerError: {}",
    "error_lex_badLineNumber_1_greaterThanNumLines": "lineNumber is greater than or equal to the number of lines",
    "error_lex_badLineNumber_2_lessThanZero": "lineNumber is less than or equal 0",
    "error_lex_badRange_1_lineNumberEnd_greaterThanLineLength": "end.lineCodeUnit is higher than line's length",
    "error_lex_badRange_2_lineNumberEnd_greaterThanLineNumbers": "end.lineNumber is higher than State's number of lines",
    "error_lex_badRange_3_lineNumberStart_greaterThanLineLength": "start.lineCodeUnit is higher than line's length",
    "error_lex_badRange_4_lineNumberStart_greaterThanLineNumberEnd": "start.lineNumber is larger than end.lineNumber",
    "error_lex_badRange_5_lineNumberStart_greaterThanNumLines": "start.lineNumber is higher than State's number of lines.",
    "error_lex_badRange_6_lineNumberStart_lessThanZero": "start.lineNumber is less than 0",
    "error_lex_badRange_7_sameLine_codeUnitStartGreaterThanCodeUnitEnd": "Start and end shared the same line, but start.lineCodeUnit was higher than end.lineCodeUnit",
    "error_lex_badState": "The lexer encountered an error last run. Either feed the lexer more text or review lastError",
    "error_lex_endOfStream": "The lexer reached end-of-stream",
    "error_lex_endOfStreamPartwayRead": "While attempting to read a token the document stream ended part way through",
    "error_lex_expectedKind_1_hex": "Expected a hex literal",
    "error_lex_expectedKind_2_keywordOrIdentifier": "Expected a keyword or identifier",
    "error_lex_expectedKind_3_numeric": "Expected a numeric literal",
    "error_lex_lineMap": "Error on line(s): {}",
    "error_lex_unexpectedRead": "Unexpected read while lexing",
    "error_lex_unterminatedMultilineToken_1_comment": "Unterminated multiline comment",
    "error_lex_unterminatedMultilineToken_2_quotedIdentifier": "Unterminated quoted identifier",
    "error_lex_unterminatedMultilineToken_3_string": "Unterminated string",
    "error_parse_csvContinuation_1_danglingComma": "Did you leave a dangling comma?",
    "error_parse_csvContinuation_2_letExpression": "A comma cannot precent an 'in'",
    "error_parse_expectAnyTokenKind_1_other": "Expected to find one of the following, but {} was found instead: {}",
    "error_parse_expectAnyTokenKind_2_endOfStream": "Expected to find one of the following, but the end-of-stream was reached instead: {}",
    "error_parse_expectGeneralizedIdentifier_1_other": "Expected to find a generalized identifier",
    "error_parse_expectGeneralizedIdentifier_2_endOfStream": "Expected to find a generalized identifier but the end-of-stream was reached first",
    "error_parse_expectTokenKind_1_other": "Expected to find {}, but found {} instead",
    "error_parse_expectTokenKind_2_endOfStream": "Expected to find {} but the end-of-stream was reached instead",
    "error_parse_invalidPrimitiveType": "Expected to find a primitive literal but {} was found instead",
    "error_parse_requiredParameterAfterOptional": "You cannot have a non-optional parameter after an optional parameter",
    "error_parse_unexpected": "You cannot have a non-optional parameter after an optional parameter",
    "error_parse_unterminated_bracket": "Unterminated bracket",
    "error_parse_unterminated_parenthesis": "Unterminated parenthesis",
    "error_parse_unusedTokens": "Finished parsing but more tokens remain",
    "tokenKind_ampersand": "ampersand (&)",
    "tokenKind_asterisk": "asterisk (*)",
    "tokenKind_atSign": "at sign (@)",
    "tokenKind_bang": "exclamation mark (!)",
    "tokenKind_comma": "comma (,)",
    "tokenKind_division": "division sign (/)",
    "tokenKind_dotDot": "dot dot (..)",
    "tokenKind_ellipsis": "ellipsis (...)",
    "tokenKind_equal": "equal sign (=)",
    "tokenKind_fatArrow": "fat arrow (=>)",
    "tokenKind_greaterThan": "greater than sign (>)",
    "tokenKind_greaterThanEqualTo": "greater than or equal to sign (>=)",
    "tokenKind_hexLiteral": "hex literal",
    "tokenKind_identifier": "identifier",
    "tokenKind_keywordAnd": "the keyword 'and'",
    "tokenKind_keywordAs": "the keyword'as'",
    "tokenKind_keywordEach": "the keyword 'each'",
    "tokenKind_keywordElse": "the keyword 'else'",
    "tokenKind_keywordError": "the keyword 'error'",
    "tokenKind_keywordFalse": "the keyword 'false'",
    "tokenKind_keywordHashBinary": "the keyword '#binary'",
    "tokenKind_keywordHashDate": "the keyword '#date'",
    "tokenKind_keywordHashDateTime": "the keyword '#datetime'",
    "tokenKind_keywordHashDateTimeZone": "the keyword '#datetimezone'",
    "tokenKind_keywordHashDuration": "the keyword '#duration'",
    "tokenKind_keywordHashInfinity": "the keyword '#infinity'",
    "tokenKind_keywordHashNan": "the keyword '#nan'",
    "tokenKind_keywordHashSections": "the keyword '#sections'",
    "tokenKind_keywordHashShared": "the keyword '#shared'",
    "tokenKind_keywordHashTable": "the keyword '#table'",
    "tokenKind_keywordHashTime": "the keyword '#time'",
    "tokenKind_keywordIf": "the keyword 'if'",
    "tokenKind_keywordIn": "the keyword 'in'",
    "tokenKind_keywordIs": "the keyword 'is'",
    "tokenKind_keywordLet": "the keyword 'let'",
    "tokenKind_keywordMeta": "the keyword 'meta'",
    "tokenKind_keywordNot": "the keyword 'not'",
    "tokenKind_keywordOr": "the keyword 'or'",
    "tokenKind_keywordOtherwise": "the keyword 'otherwise'",
    "tokenKind_keywordSection": "the keyword 'section'",
    "tokenKind_keywordShared": "the keyword 'shared'",
    "tokenKind_keywordThen": "the keyword 'then'",
    "tokenKind_keywordTrue": "the keyword 'true'",
    "tokenKind_keywordTry": "the keyword 'try'",
    "tokenKind_keywordType": "the keyword 'type'",
    "tokenKind_leftBrace": "'{'",
    "tokenKind_leftBracket": "'['",
    "tokenKind_leftParenthesis": "'('",
    "tokenKind_lessThan": "less than sign (<)",
    "tokenKind_lessThanEqualTo": "less than or equal to sign (<=)",
    "tokenKind_minus": "minus (-)",
    "tokenKind_notEqual": "not equal to sign (<>)",
    "tokenKind_nullLiteral": "null",
    "tokenKind_numericLiteral": "numeric literal",
    "tokenKind_plus": "plus sign (+)",
    "tokenKind_questionMark": "question mark (?)",
    "tokenKind_rightBrace": "'}'",
    "tokenKind_rightBracket": "']'",
    "tokenKind_rightParenthesis": "')'",
    "tokenKind_semicolon": "semicolon (;)",
    "tokenKind_stringLiteral": "string"
}
